---
layout: post
title: Image recognition with TensorFlow
---

Data: [MNIST dataset](http://yann.lecun.com/exdb/mnist/)  
Techniques: Image recognition, neural networks


---


Here I go through the workflow of using TensorFlow to recognize handwritten digits from the [MNIST data](http://yann.lecun.com/exdb/mnist/). This dataset has images of integers from 0 to 9, as well as labels indicating the digit they represent.


```python
import numpy as np
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import matplotlib.pyplot as plt
%matplotlib inline
```

### The data:


```python
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
```




```python
print("Number of training examples:", mnist.train.num_examples)
print("Number of validation examples:", mnist.validation.num_examples)
print("Number of testing examples:", mnist.test.num_examples)
```

    Number of training examples: 55000
    Number of validation examples: 5000
    Number of testing examples: 10000



```python
print(mnist.train.images.shape, mnist.train.labels.shape)
print(mnist.validation.images.shape, mnist.validation.labels.shape)
print(mnist.test.images.shape, mnist.test.labels.shape)
```

    (55000, 784) (55000, 10)
    (5000, 784) (5000, 10)
    (10000, 784) (10000, 10)


Each image is 28 x 28 pixels, which we can interpret as a big array of numbers. We will flatten this array into a vector of 28x28=784 numbers (this does throw away the 2D structure of the image).

The result is that mnist.train.images is a tensor (n-dim array) with shape [55000,784] (55,000 comes from the fact that we have 55,000 training points). The first dim is an index into the list of images, the second dim is the index for each pixel in each image. Each entry in the tensor is a pixel intensity between 0 and 1.

Labels from 0 to 9 are one-hot encoded.

#### Looking at the data:


```python
left= 2.5
top = 2.5

fig = plt.figure(figsize=(10,10))

for i in range(6):
    ax = fig.add_subplot(3,2,i+1)
    im = np.reshape(mnist.train.images[i,:], [28,28])

    label = np.argmax(mnist.train.labels[i,:])
    ax.imshow(im, cmap='Greys')
    ax.text(left, top, str(label))
```


![png](/images/mnist_output_8_0.png)


### Training a model to identify digit
This is a many-class classificiation. We will train a model for each class- we will train a set of weights that will be used to calculate a weighted sum of all the pixel intensities in the image.

#### Setup:


```python
# A placeholder for the data (inputs and outputs)
x = tf.placeholder(tf.float32, [None, 784])

# W: the weights for each pixel for each class
# b: bias of each class
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))
```

#### Softmax:

We want to give probabilities that a given image is a digit. Softmax regression gives a list of values between 0 and 1 that add up to 1. We could also train more sophisticated models, with a final step of a layer of softmax (it's a link or activation function).

Two steps to softmax:  
1. Add up evidence of input being in a certain class by using a weighted sum of pixel intensities. The weight is negative if that pixel having high intensity is evidence against the image being in that class, and positive if it is evidence in favor.    
2. Convert the evidence into probabilities.  


```python
# The model
y = tf.nn.softmax(tf.matmul(x, W) + b)
```

#### Training:


```python
# placeholder to input correct answers
y_ = tf.placeholder(tf.float32, [None, 10])

# A measure of model precision using cross-entropy
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
```


```python
# ask TensorFLow to minimize cross_entropy with gradient descent
# with 0.5 as learning rate
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
```


```python
init = tf.global_variables_initializer()

# the execution
sess = tf.Session()
sess.run(init)

# run training step 1000 times
for i in range(1000):
    
    # get random 100 data samples from the training set
    batch_xs, batch_ys = mnist.train.next_batch(100)
    
    # feed them to the model in place of the placeholders defined above
    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
```

#### Evaluating:

tf.argmax gives the index of the highest entry in a tensor along some axis- therfore checking if these indices are equal will return a Boolean array:


```python
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))

#this accuracy returns the mean value of an array of 1s and 0s.
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

# retrun the accuracy on the test set.
print("Accuracy: ", sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
```

    Accuracy:  0.9194


Our model is about 92% accurate.

#### Misclassified images:
Let's look at some of the ones that were misclassified.


```python
correct_vals = sess.run(correct_prediction, 
                        feed_dict={x: mnist.train.images, y_: mnist.train.labels})
pred_vals = sess.run(y, feed_dict={x: mnist.train.images} )

cntFalse = 0
for cv in correct_vals:
    if cv==False:
        cntFalse+=1
print(cntFalse, "incorrect labels out of",  len(correct_vals))


fig = plt.figure(figsize=(10,10))

cntFalse = 0
for i, cv in enumerate(correct_vals):
    
    if cv==False:
        cntFalse +=1

        ax = fig.add_subplot(3,2,cntFalse)
        im = np.reshape(mnist.train.images[i,:], [28,28])

        label = np.argmax(mnist.train.labels[i,:])
        pred_label = np.argmax(pred_vals[i,:])
        
        ax.imshow(im, cmap='Greys')
        ax.text(left, top, 'true=' + str(label) + ', pred=' + str(pred_label))
        
    if cntFalse==6:
        break
```

    4522 incorrect labels out of 55000



![png](/images/output_23_1.png)


A visual inspection gives an idea of where the model fails; in some cases the digit is in the wrong orientation, or there are missing pixels, or the predicted number shares many high intensity pixels with the true digit. 


```python
sess.close()
```
